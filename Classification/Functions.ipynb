{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env import host, user, password\n",
    "\n",
    "def get_url(db):\n",
    "    return f'mysql+pymysql://{user}:{password}@{host}/{db}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'util'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-ae30409de341>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# In a new python module, acquire.py:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'util'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import util\n",
    "\n",
    "# In a new python module, acquire.py:\n",
    "def get_data(query,db):\n",
    "    return pd.read_sql(query, util.get_url(db))\n",
    "\n",
    "# get_titanic_data: returns the titanic data from the codeup data science database as a pandas data frame.\n",
    "def get_titanic_data():\n",
    "    query = \"SELECT * FROM passengers\"\n",
    "    db = \"titanic_db\"\n",
    "    return pd.read_sql(query, util.get_url(db))\n",
    "\n",
    "# get_iris_data: returns the data from the iris_db on the codeup data science database as a pandas data frame. The returned data frame should include the actual name of the species in addition to the species_ids.\n",
    "\n",
    "def get_iris_data():\n",
    "    query = \"\"\"\n",
    "    SELECT * FROM measurements\n",
    "    JOIN species USING (species_id)\n",
    "    \"\"\"\n",
    "    db = \"iris_db\"\n",
    "    return pd.read_sql(query, util.get_url(db))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def prep_iris(df):\n",
    "    df.drop(columns = [\"species_id\",\"measurement_id\"],inplace=True)\n",
    "    df.rename(columns={\"species_name\":\"species\"}, inplace=True)\n",
    "    encoder = LabelEncoder()\n",
    "    \n",
    "    encoder.fit(df.species)\n",
    "    df.species = encoder.transform(df.species)\n",
    "    return df, encoder\n",
    "\n",
    "def prep_titanic(df):\n",
    "    df.fillna(np.nan,inplace=True)\n",
    "\n",
    "    imp_mode = SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\")\n",
    "    imp_mode.fit(df[[\"embarked\",\"embark_town\"]])\n",
    "    df[[\"embarked\",\"embark_town\"]] = imp_mode.transform(df[[\"embarked\",\"embark_town\"]])\n",
    "    \n",
    "    df.drop(columns=\"deck\", inplace=True)\n",
    "    \n",
    "    encoder = LabelEncoder()\n",
    "    df.embarked = encoder.fit_transform(df.embarked)\n",
    "    scaler = MinMaxScaler()\n",
    "    df[[\"age\",\"fare\"]] = scaler.fit_transform(df[[\"age\",\"fare\"]])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, QuantileTransformer, PowerTransformer, RobustScaler, MinMaxScaler\n",
    "\n",
    "# split_my_data(df, train_pct)\n",
    "def split_my_data(df, train_pct):\n",
    "    train, test = train_test_split(df, train_size=train_pct, random_state=123)\n",
    "    return train, test\n",
    "\n",
    "def transform_scaler(train, test, scaler):  \n",
    "    train_scaled = pd.DataFrame(scaler.transform(train), columns=train.columns.values).set_index([train.index.values])\n",
    "    test_scaled = pd.DataFrame(scaler.transform(test), columns=test.columns.values).set_index([test.index.values])\n",
    "    return train_scaled, test_scaled\n",
    "\n",
    "# standard_scaler()\n",
    "def standard_scaler(train, test):\n",
    "    scaler = StandardScaler(copy=True, with_mean=True, with_std=True).fit(train)\n",
    "    train_scaled, test_scaled = transform_scaler(train, test, scaler)\n",
    "\n",
    "    return train_scaled, test_scaled, scaler\n",
    "\n",
    "# scale_inverse()\n",
    "def scale_inverse(train_scaled, test_scaled, scaler):\n",
    "    train_unscaled = pd.DataFrame(scaler.inverse_transform(train_scaled), columns=train_scaled.columns.values).set_index([train_scaled.index.values])\n",
    "    test_unscaled = pd.DataFrame(scaler.inverse_transform(test_scaled), columns=test_scaled.columns.values).set_index([test_scaled.index.values])\n",
    " \n",
    "    return train_unscaled, test_unscaled\n",
    "\n",
    "# uniform_scaler()\n",
    "def uniform_scaler(train, test):\n",
    "    scaler = QuantileTransformer(n_quantiles=100, output_distribution='uniform', random_state=123, copy=True).fit(train)\n",
    "\n",
    "    train_scaled, test_scaled = transform_scaler(train, test, scaler)\n",
    "\n",
    "    return train_scaled, test_scaled, scaler   \n",
    "\n",
    "# gaussian_scaler()\n",
    "def gaussian_scaler(train, test):\n",
    "    scaler = PowerTransformer(method='yeo-johnson', standardize=False, copy=True).fit(train)\n",
    "\n",
    "    train_scaled, test_scaled = transform_scaler(train, test, scaler)\n",
    "\n",
    "    return train_scaled, test_scaled, scaler\n",
    " \n",
    "# min_max_scaler()\n",
    "def min_max_scaler(train, test):\n",
    "    scaler = MinMaxScaler(copy=True, feature_range=(0,1)).fit(train)\n",
    "    train_scaled, test_scaled = transform_scaler(train, test, scaler)\n",
    "\n",
    "    return train_scaled, test_scaled, scaler\n",
    " \n",
    "# iqr_robust_scaler()\n",
    "def iqr_robust_scaler(train, test):\n",
    "    scaler = RobustScaler(quantile_range=(25.0,75.0), copy=True, with_centering=True, with_scaling=True).fit(train)\n",
    "\n",
    "    train_scaled, test_scaled = transform_scaler(train, test, scaler)\n",
    "\n",
    "    return train_scaled, test_scaled, scaler  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "def object_subplots(df):\n",
    "\n",
    "    features = df.columns [(df.dtypes == object) & (df.nunique() < 5)]\n",
    "    \n",
    "    _, ax = plt.subplots(nrows=1, ncols=len(features), figsize=(16,5))\n",
    "\n",
    "    survival_rate = df.survived.mean()\n",
    "\n",
    "    for i, feature in enumerate(features):\n",
    "        sns.barplot(feature, 'survived', data=df, ax=ax[i], alpha=.5)\n",
    "        ax[i].set_ylabel('Survival Rate')\n",
    "        ax[i].axhline(survival_rate, ls='--', color='grey')\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
